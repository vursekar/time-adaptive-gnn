{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95dc4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should be exactly the same between all models\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common import *\n",
    "from util import *\n",
    "\n",
    "# Load everything\n",
    "scaled_data = {}\n",
    "with np.load(PREPROCESSED_DATASET_FILEPATH) as npz_loader:\n",
    "    for key in npz_loader:\n",
    "        scaled_data[key] = npz_loader[key]\n",
    "scaler = pk.load(open(PREPROCESSING_SCALER_FILEPATH, \"rb\"))\n",
    "\n",
    "# Input and output dims\n",
    "input_shape = tuple(list(scaled_data['x_train'].shape)[1:])\n",
    "output_shape = tuple(list(scaled_data['y_train'].shape)[1:])\n",
    "input_dims = np.product(input_shape)\n",
    "output_dims = np.product(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "096ed454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.8.0\n",
      "numpy: 1.21.5\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorflow: {}\".format(tf.__version__))\n",
    "print(\"numpy: {}\".format(np.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e45cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS:\n",
    "MODEL_NAME = \"Feedforward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99d2c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct TF model here\n",
    "\n",
    "# Simple Feedforward Neural Network\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=512,activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "#         tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(units=512,activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "#         tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(units=output_dims,activation='linear'),\n",
    "        tf.keras.layers.Reshape(output_shape)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c038497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (5, 4968)                 0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (5, 512)                  2544128   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (5, 512)                  262656    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (5, 4968)                 2548584   \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (5, 12, 207, 2)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,355,368\n",
      "Trainable params: 5,355,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters and callbacks\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch<50:\n",
    "        return lr\n",
    "    elif epoch%20==0:\n",
    "        return lr/10\n",
    "    else:\n",
    "        return lr\n",
    "    \n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "model(scaled_data['x_train'][:5])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b2307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/375 [..............................] - ETA: 1:46 - loss: 2.2197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 12:30:24.525698: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/375 [============================>.] - ETA: 0s - loss: 0.4553"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 12:30:27.036120: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4543 - val_loss: 0.2798 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2466 - val_loss: 0.2315 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.2292 - val_loss: 0.2263 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2219 - val_loss: 0.2262 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2157 - val_loss: 0.2242 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.2127 - val_loss: 0.2269 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2094 - val_loss: 0.2149 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2044 - val_loss: 0.2130 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2025 - val_loss: 0.2095 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2008 - val_loss: 0.2149 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1990 - val_loss: 0.2114 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1965 - val_loss: 0.2111 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1976 - val_loss: 0.2063 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1965 - val_loss: 0.2245 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1947 - val_loss: 0.2120 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1951 - val_loss: 0.2050 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1948 - val_loss: 0.2045 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1935 - val_loss: 0.2048 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1930 - val_loss: 0.2027 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1920 - val_loss: 0.2016 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1929 - val_loss: 0.2119 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1923 - val_loss: 0.2089 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1932 - val_loss: 0.2070 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1905 - val_loss: 0.2067 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1899 - val_loss: 0.2175 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1914 - val_loss: 0.2032 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1877 - val_loss: 0.2010 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1873 - val_loss: 0.2015 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1869 - val_loss: 0.2058 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1861 - val_loss: 0.2013 - lr: 0.0010\n",
      "Epoch 31/100\n",
      " 19/375 [>.............................] - ETA: 2s - loss: 0.1894"
     ]
    }
   ],
   "source": [
    "# Compile and fit model here\n",
    "history = model.fit(\n",
    "    x=scaled_data['x_train'],\n",
    "    y=scaled_data['y_train'],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=MAX_EPOCHS,\n",
    "    validation_data=(scaled_data['x_val'],\n",
    "    scaled_data['y_val']),\n",
    "    callbacks=[callback_lr,callback_es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e2aa55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 12:30:03.659151: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Compute unnormalized prediction loss\n",
    "\n",
    "preds = {}\n",
    "\n",
    "for split in ['test','val']:\n",
    "    preds[split] = model.predict(scaled_data['x_'+split])\n",
    "    preds[split] = scaler.inverse_transform(preds[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b32541d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(model_name_to_model_filepath(MODEL_NAME))\n",
    "\n",
    "# Save run info\n",
    "run_info = {}\n",
    "run_info[\"history\"] = history.history\n",
    "run_info[\"predictions\"] = preds # idk whether this part makes sense for RNNs or not\n",
    "pk.dump(run_info, open(model_name_to_run_info_filepath(MODEL_NAME), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb5467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
