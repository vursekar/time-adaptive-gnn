{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95dc4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should be exactly the same between all models\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common import *\n",
    "from util import *\n",
    "\n",
    "# Load everything\n",
    "scaled_data = {}\n",
    "with np.load(PREPROCESSED_DATASET_FILEPATH) as npz_loader:\n",
    "    for key in npz_loader:\n",
    "        scaled_data[key] = npz_loader[key]\n",
    "scaler = pk.load(open(PREPROCESSING_SCALER_FILEPATH, \"rb\"))\n",
    "\n",
    "# Input and output dims\n",
    "input_shape = tuple(list(scaled_data['x_train'].shape)[1:])\n",
    "output_shape = tuple(list(scaled_data['y_train'].shape)[1:])\n",
    "input_dims = np.product(input_shape)\n",
    "output_dims = np.product(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096ed454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.8.0\n",
      "numpy: 1.21.5\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorflow: {}\".format(tf.__version__))\n",
    "print(\"numpy: {}\".format(np.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e45cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS:\n",
    "MODEL_NAME = \"LSTM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d2c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 14:46:27.315045: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-17 14:46:27.315335: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Reshape((12,-1)),\n",
    "                             tf.keras.layers.LSTM(256, activation='tanh',return_sequences=True),\n",
    "                             tf.keras.layers.LSTM(256, activation='tanh',return_sequences=False),\n",
    "                             tf.keras.layers.Dense(output_dims, activation='linear',\n",
    "                                                   kernel_initializer='glorot_uniform',),\n",
    "                             tf.keras.layers.Reshape(output_shape)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c038497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters and callbacks\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch<50:\n",
    "        return lr\n",
    "    elif epoch%20==0:\n",
    "        return lr/10\n",
    "    else:\n",
    "        return lr\n",
    "    \n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3b2307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 14:46:32.580897: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-17 14:46:33.894441: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 14:46:34.075630: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 14:46:34.132475: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 14:46:34.214462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 14:46:34.279261: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - ETA: 0s - loss: 0.2174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 14:46:42.895148: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 14:46:42.964256: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 14:46:42.993920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 11s 17ms/step - loss: 0.2174 - val_loss: 0.2100 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "570/570 [==============================] - 9s 15ms/step - loss: 0.1798 - val_loss: 0.1965 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1706 - val_loss: 0.2008 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1657 - val_loss: 0.1975 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1617 - val_loss: 0.1944 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1579 - val_loss: 0.1957 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1568 - val_loss: 0.1918 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1532 - val_loss: 0.1895 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1530 - val_loss: 0.1871 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "570/570 [==============================] - 9s 15ms/step - loss: 0.1497 - val_loss: 0.1773 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1497 - val_loss: 0.1873 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "570/570 [==============================] - 9s 15ms/step - loss: 0.1474 - val_loss: 0.1880 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1464 - val_loss: 0.1881 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1457 - val_loss: 0.1838 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "570/570 [==============================] - 9s 15ms/step - loss: 0.1364 - val_loss: 0.1708 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1417 - val_loss: 0.1849 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "570/570 [==============================] - 9s 15ms/step - loss: 0.1283 - val_loss: 0.1924 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1434 - val_loss: 0.1877 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1344 - val_loss: 0.1746 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1248 - val_loss: 0.1662 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1255 - val_loss: 0.1649 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1164 - val_loss: 0.1890 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "570/570 [==============================] - 9s 15ms/step - loss: 0.1246 - val_loss: 0.1893 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1177 - val_loss: 0.1658 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1240 - val_loss: 0.1878 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "570/570 [==============================] - 9s 15ms/step - loss: 0.1220 - val_loss: 0.1624 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1131 - val_loss: 0.1607 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "570/570 [==============================] - 9s 15ms/step - loss: 0.1236 - val_loss: 0.1887 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1264 - val_loss: 0.1647 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "570/570 [==============================] - 9s 15ms/step - loss: 0.1258 - val_loss: 0.1876 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1188 - val_loss: 0.1656 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1094 - val_loss: 0.1632 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1084 - val_loss: 0.1999 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1071 - val_loss: 0.1720 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1051 - val_loss: 0.1609 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "570/570 [==============================] - 9s 16ms/step - loss: 0.1046 - val_loss: 0.1653 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "570/570 [==============================] - 9s 15ms/step - loss: 0.1029 - val_loss: 0.1608 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit model here\n",
    "history = model.fit(\n",
    "    x=scaled_data['x_train'],\n",
    "    y=scaled_data['y_train'],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=MAX_EPOCHS,\n",
    "    validation_data=(scaled_data['x_val'],\n",
    "    scaled_data['y_val']),\n",
    "    callbacks=[callback_lr,callback_es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e2aa55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 14:57:51.662154: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 14:57:51.726110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 14:57:51.757651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Compute unnormalized prediction loss\n",
    "\n",
    "preds = {}\n",
    "\n",
    "for split in ['test','val']:\n",
    "    preds[split] = model.predict(scaled_data['x_'+split])\n",
    "    preds[split] = scaler.inverse_transform(preds[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b32541d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(model_name_to_model_filepath(MODEL_NAME))\n",
    "\n",
    "# Save run info\n",
    "run_info = {}\n",
    "run_info[\"history\"] = history.history\n",
    "run_info[\"predictions\"] = preds # idk whether this part makes sense for RNNs or not\n",
    "pk.dump(run_info, open(model_name_to_run_info_filepath(MODEL_NAME), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb58e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
