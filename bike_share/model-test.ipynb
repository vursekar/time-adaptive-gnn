{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591914d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data_directory = \"processed_data\"\n",
    "data_filename_base = \"X_top300_201801_201912_30_m_final\"\n",
    "data_filename_ext = \".npz\"\n",
    "data_filename = data_filename_base+data_filename_ext\n",
    "\n",
    "data = {}\n",
    "with np.load(os.path.join(data_directory, data_filename)) as npz_loader:\n",
    "    for key in npz_loader.files:\n",
    "        print(\"{}: {}\".format(key, npz_loader[key].shape))\n",
    "        data[key] = npz_loader[key]\n",
    "\n",
    "X_train = data[\"X_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "X_val = data[\"X_val\"]\n",
    "y_val = data[\"y_val\"]\n",
    "X_test = data[\"X_test\"]\n",
    "y_test = data[\"y_test\"]\n",
    "\n",
    "\n",
    "input_shape = tuple(list(X_train.shape)[1:])\n",
    "output_shape = tuple(list(y_train.shape)[1:])\n",
    "input_dims = np.product(input_shape)\n",
    "output_dims = np.product(output_shape)\n",
    "\n",
    "num_nodes, num_steps, input_features = input_shape\n",
    "_, _, output_features = output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fnn import FNN\n",
    "from models.linear import LinearRegressor\n",
    "from models.fclstm import FCLSTM\n",
    "from models.stgcn import STGCN\n",
    "from models.wavenet import GraphWaveNet, GraphConv\n",
    "\n",
    "model_types = {'FNN': FNN, 'LinearRegressor': LinearRegressor,\n",
    "               'FCLSTM': FCLSTM, 'STGCN': STGCN, 'GraphWaveNet': GraphWaveNet}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from specs_to_run import *\n",
    "\n",
    "training_specs, model_params = models_to_run['STGCN_adaptiveA']\n",
    "\n",
    "MODEL_CLASS = model_types[training_specs['model_type']]\n",
    "BATCH_SIZE = training_specs['batch_size']\n",
    "MAX_EPOCHS = training_specs['max_epochs']\n",
    "PATIENCE = training_specs['patience']\n",
    "LOSS_TYPE = training_specs['loss_type']\n",
    "LEARNING_RATE = training_specs['learning_rate']\n",
    "\n",
    "callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed=10707)\n",
    "\n",
    "model = MODEL_CLASS(model_params)\n",
    "\n",
    "model.compile(loss=LOSS_TYPE, optimizer=tf.keras.optimizers.Adam(LEARNING_RATE))\n",
    "print(model(X_train[:32]).shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train, y=y_train, shuffle=True,\n",
    "                    batch_size=BATCH_SIZE, epochs=MAX_EPOCHS,\n",
    "                    validation_data=(X_val,y_val),\n",
    "                    callbacks=[callback_es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a4a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "plt.figure()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(LOSS_TYPE)\n",
    "plt.plot(history.history['loss'],label=training_specs['model_name']+'_train')\n",
    "plt.plot(history.history['val_loss'],label=training_specs['model_name']+'_val')\n",
    "plt.legend()\n",
    "\n",
    "print(training_specs['model_name']+\" test Loss = \", model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1753e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "ground_truth = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_store_directory = \"stored_models\"\n",
    "run_info_store_directory = \"stored_models\"\n",
    "\n",
    "if training_specs['save_model']:\n",
    "    model_store_filename = \"_\".join([training_specs['model_name'], \"model\"])\n",
    "    model_store_filepath = os.path.join(model_store_directory, model_store_filename)\n",
    "    model.save(model_store_filepath, save_format=\"tf\")\n",
    "\n",
    "if training_specs['save_model_history']:\n",
    "    run_info = {}\n",
    "    run_info[\"train_test_path\"] = data_filename\n",
    "    run_info[\"history\"] = history.history\n",
    "    run_info[\"predictions\"] = predictions\n",
    "\n",
    "    run_info_store_filename = \"_\".join([training_specs['model_name'], \"run_info\"]) + \".pk\"\n",
    "    run_info_store_filepath = os.path.join(run_info_store_directory, run_info_store_filename)\n",
    "    pk.dump(run_info, open(run_info_store_filepath, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = 50\n",
    "horizon = 8\n",
    "feature = 0\n",
    "feature_labels = {0: 'Demand', 1: 'Supply'}\n",
    "\n",
    "horizon_predictions = seq_from_windows(predictions, horizon=horizon)\n",
    "horizon_ground_truth = seq_from_windows(y_test, horizon=horizon)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.xlim(6000,7000)\n",
    "plt.title(f\"Prediction horizon = {horizon * 30} min\")\n",
    "plt.xlabel(\"Time / 30 min\")\n",
    "plt.ylabel(f\"{feature_labels[feature]} at station {station}\")\n",
    "plt.plot(horizon_predictions[station,:,feature],label=training_specs['model_name'])\n",
    "plt.plot(horizon_ground_truth[station,:,feature],label='ground truth')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec45eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
